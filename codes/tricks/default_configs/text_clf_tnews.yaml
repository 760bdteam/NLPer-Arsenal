task_name: 'text_clf'

# data config
dataset_name: tnews
use_convert: True  # 是否将数据转换成标准格式？对于非标准数据集，必须为True
preprocess_method: None
num_class: 15
train_file: '../data/tnews/train.json'
val_file: '../data/tnews/dev.json'
test_file: '../data/tnews/test.json'

# model config
model_type: 'bert'  # 选择dataset类时用到，非Bert类型时必须指定为None，否则指定为‘bert’
pretrained_model: 'bert-base-chinese'  # plm需指定预训练模型
whole_model: 'BertCLF'  # 指定完整的模型，目前只有BertCLF
dropout: 0.1
component_model:  # 指定具体的模型组件，如果指定了完整模型，可忽略；ps：这个还没有实现
  embedding: ''
  encoder: ''
  decoder: ''

# other config
is_train: True
is_test: True
max_len: 128
seed: 42  #
train_batch_size: 16
val_batch_size: 8  # test_batch_size too
lr: !!float 2e-5
weight_decay: 0.01
warmup_steps: 200
metrics: [ 'P', 'R', 'F1' ]
target_metric: 'F1'
checkpoint: None
out_dir: 'saved/'

# mpl.trainer
trainer_args:
  gpus: [7]  # List[int]/str/int/None
  max_epochs: 3